"""
Data Processor - Chuy·ªÉn ƒë·ªïi output LLM sang format ADACS

X·ª≠ l√Ω v√† chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ t·ª´ LLM th√†nh format ADACS chu·∫©n.
T√≠ch h·ª£p pronunciation engine ƒë·ªÉ auto-fix c√°c l·ªói phi√™n √¢m.

T√≠nh nƒÉng ch√≠nh:
- Parse v√† validate JSON output t·ª´ LLM
- Auto-fix t·ª´ ti·∫øng Anh ch∆∞a ƒë∆∞·ª£c phi√™n √¢m
- X√¢y d·ª±ng spoken text v·ªõi phi√™n √¢m ch√≠nh x√°c
- Tr√≠ch xu·∫•t English phrases t·ª´ origin text

Author: Dataset Generator Team
"""

import json
import re
from typing import Dict, List, Tuple, Optional


class DataProcessor:
    """
    L·ªõp x·ª≠ l√Ω d·ªØ li·ªáu ch√≠nh trong pipeline.
    
    Chuy·ªÉn ƒë·ªïi output t·ª´ LLM th√†nh format ADACS chu·∫©n v√† t·ª± ƒë·ªông
    s·ª≠a c√°c l·ªói phi√™n √¢m ph·ªï bi·∫øn.
    
    Attributes:
        pronunciation_engine: Engine x·ª≠ l√Ω phi√™n √¢m ti·∫øng Anh
    """
    def __init__(self, pronunciation_engine, use_ai_pronunciation: bool = False, ai_client=None):
        """
        Kh·ªüi t·∫°o DataProcessor v·ªõi pronunciation engine.
        
        Args:
            pronunciation_engine: Instance c·ªßa PronunciationEngine ƒë·ªÉ x·ª≠ l√Ω phi√™n √¢m
            use_ai_pronunciation: (Deprecated - b·ªã b·ªè qua)
            ai_client: (Deprecated - b·ªã b·ªè qua)
        """
        self.pronunciation_engine = pronunciation_engine
    
    def parse_llm_response(self, response: str) -> Optional[Dict]:
        """
        Ph√¢n t√≠ch response t·ª´ LLM ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu c√≥ c·∫•u tr√∫c.
        
        Args:
            response: Raw response t·ª´ LLM (string JSON)
            
        Returns:
            Dict ƒë√£ parse - ADACS format ho·∫∑c simple format
            None n·∫øu parse th·∫•t b·∫°i
        """
        try:
            # Remove markdown code blocks if present
            response = response.strip()
            response = re.sub(r'^```json\s*', '', response)
            response = re.sub(r'\s*```$', '', response)
            
            # Parse JSON
            data = json.loads(response)
            
            # Check if it's ADACS format (direct from LLM)
            adacs_fields = ["origin", "spoken", "en_word", "vi_spoken_word", "type", "en_phrase"]
            if all(field in data for field in adacs_fields):
                return data
            
            # Check if it's simple format (needs processing)
            simple_fields = ["text", "context", "en_words", "difficulty"]
            if all(field in data for field in simple_fields):
                return data
            
            # If neither format matches
            print(f"Missing required fields in LLM response: {data}")
            return None
                
        except json.JSONDecodeError as e:
            print(f"Failed to parse JSON from LLM response: {e}")
            print(f"Response: {response[:200]}...")
            return None
        except Exception as e:
            print(f"Error parsing LLM response: {e}")
            return None
    
    def extract_english_phrases(self, text: str, en_words: List[str]) -> List[str]:
        """
        Tr√≠ch xu·∫•t c√°c c·ª•m t·ª´ ti·∫øng Anh t·ª´ vƒÉn b·∫£n.
        
        Args:
            text: VƒÉn b·∫£n g·ªëc ch·ª©a c√°c t·ª´ ti·∫øng Anh
            en_words: Danh s√°ch c√°c t·ª´ ti·∫øng Anh r·ªùi r·∫°c
            
        Returns:
            Danh s√°ch c√°c phrase ti·∫øng Anh (bao g·ªìm t·ª´ ƒë∆°n v√† c·ª•m t·ª´)
        """
        phrases = []
        
        # Add all individual words
        phrases.extend(en_words)
        
        # Find multi-word phrases (consecutive English words)
        words_in_text = text.split()
        
        i = 0
        while i < len(words_in_text):
            # Check if current word is English
            if words_in_text[i] in en_words:
                # Try to build a phrase
                phrase_words = [words_in_text[i]]
                j = i + 1
                
                while j < len(words_in_text) and words_in_text[j] in en_words:
                    phrase_words.append(words_in_text[j])
                    j += 1
                
                # If we found a multi-word phrase, add it
                if len(phrase_words) > 1:
                    phrases.append(" ".join(phrase_words))
                
                i = j
            else:
                i += 1
        
        # Remove duplicates while preserving order
        seen = set()
        unique_phrases = []
        for phrase in phrases:
            if phrase not in seen:
                seen.add(phrase)
                unique_phrases.append(phrase)
        
        return unique_phrases
    
    def build_adacs_format(self, 
                          origin_text: str, 
                          en_words: List[str],
                          context: str,
                          difficulty: str) -> Dict:
        """
        X√¢y d·ª±ng entry ho√†n ch·ªânh theo format ADACS.
        
        Args:
            origin_text: VƒÉn b·∫£n ti·∫øng Vi·ªát g·ªëc c√≥ ch·ª©a t·ª´ ti·∫øng Anh
            en_words: Danh s√°ch c√°c t·ª´ ti·∫øng Anh
            context: B·ªëi c·∫£nh cu·ªôc h·ªçp
            difficulty: M·ª©c ƒë·ªô kh√≥
            
        Returns:
            Dict ho√†n ch·ªânh theo format ADACS
        """
        # Generate Vietnamese pronunciations for English words
        vi_spoken_words = self.pronunciation_engine.transcribe_multiple(en_words)
        
        # Validate and auto-fix pronunciations
        vi_spoken_words = self._validate_and_fix_pronunciations(en_words, vi_spoken_words)
        
        # Build spoken text (lowercase, with pronunciations)
        spoken_text = self._build_spoken_text(origin_text, en_words, vi_spoken_words)
        
        # Extract English phrases
        en_phrases = self.extract_english_phrases(origin_text, en_words)
        
        # Build complete entry
        entry = {
            "origin": origin_text,
            "spoken": spoken_text,
            "en_word": en_words,
            "vi_spoken_word": vi_spoken_words,
            "type": difficulty,
            "en_phrase": en_phrases
        }
        
        return entry
    
    def _validate_and_fix_pronunciations(self, en_words: List[str], vi_spoken_words: List[str]) -> List[str]:
        """
        Validate v√† t·ª± ƒë·ªông s·ª≠a phi√™n √¢m n·∫øu c·∫ßn
        
        Args:
            en_words: Danh s√°ch c√°c t·ª´ ti·∫øng Anh
            vi_spoken_words: Danh s√°ch phi√™n √¢m ti·∫øng Vi·ªát t·ª´ LLM
            
        Returns:
            Danh s√°ch phi√™n √¢m ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói
        """
        fixed_pronunciations = []
        
        for en_word, vi_word in zip(en_words, vi_spoken_words):
            # Ki·ªÉm tra xem vi_word c√≥ ph·∫£i l√† ti·∫øng Anh kh√¥ng (t·ª©c l√† LLM kh√¥ng phi√™n √¢m)
            # N·∫øu gi·ªëng y h·ªát t·ª´ g·ªëc (lowercase) => ch∆∞a ƒë∆∞·ª£c phi√™n √¢m
            if vi_word.lower() == en_word.lower():
                # Auto-fix: G·ªçi pronunciation engine
                corrected = self.pronunciation_engine.transcribe(en_word)
                print(f"  ‚ö†Ô∏è  Auto-fixed: '{en_word}' ‚Üí '{corrected}' (was '{vi_word}')")
                fixed_pronunciations.append(corrected)
            else:
                fixed_pronunciations.append(vi_word)
        
        return fixed_pronunciations
    
    def _build_spoken_text(self, 
                          origin_text: str, 
                          en_words: List[str], 
                          vi_spoken_words: List[str]) -> str:
        """
        X√¢y d·ª±ng spoken text b·∫±ng c√°ch thay th·∫ø c√°c t·ª´ ti·∫øng Anh b·∫±ng phi√™n √¢m.
        
        Args:
            origin_text: VƒÉn b·∫£n g·ªëc
            en_words: Danh s√°ch c√°c t·ª´ ti·∫øng Anh
            vi_spoken_words: Danh s√°ch phi√™n √¢m ti·∫øng Vi·ªát
            
        Returns:
            VƒÉn b·∫£n spoken (ch·ªØ th∆∞·ªùng, c√≥ phi√™n √¢m)
        """
        # Start with lowercase origin
        spoken = origin_text.lower()
        
        # Create replacement mapping
        replacements = {}
        for en_word, vi_word in zip(en_words, vi_spoken_words):
            replacements[en_word.lower()] = vi_word
        
        # Sort by length (longest first) to handle overlapping words
        sorted_en_words = sorted(replacements.keys(), key=len, reverse=True)
        
        # Replace English words with Vietnamese pronunciations
        for en_word in sorted_en_words:
            # Use word boundaries to avoid partial replacements
            pattern = r'\b' + re.escape(en_word) + r'\b'
            spoken = re.sub(pattern, replacements[en_word], spoken, flags=re.IGNORECASE)
        
        return spoken
    
    def process_llm_to_adacs(self, llm_response: str) -> Optional[Dict]:
        """
        Pipeline ho√†n ch·ªânh: LLM response ‚Üí ADACS format.
        
        Args:
            llm_response: Raw response t·ª´ LLM
            
        Returns:
            Entry ADACS format ho√†n ch·ªânh ho·∫∑c None n·∫øu x·ª≠ l√Ω th·∫•t b·∫°i
        """
        # Parse LLM response
        parsed = self.parse_llm_response(llm_response)
        if not parsed:
            return None
        
        # Check if it's already in ADACS format
        adacs_fields = ["origin", "spoken", "en_word", "vi_spoken_word", "type", "en_phrase"]
        if all(field in parsed for field in adacs_fields):
            # Already in ADACS format, but VALIDATE AND FIX pronunciations
            print("\n  üîç Validating LLM-generated pronunciations...")
            
            # Validate and fix vi_spoken_word
            original_vi_words = parsed["vi_spoken_word"].copy() if isinstance(parsed["vi_spoken_word"], list) else []
            parsed["vi_spoken_word"] = self._validate_and_fix_pronunciations(
                parsed["en_word"], 
                parsed["vi_spoken_word"]
            )
            
            # Rebuild spoken text with corrected pronunciations
            parsed["spoken"] = self._build_spoken_text(
                parsed["origin"],
                parsed["en_word"],
                parsed["vi_spoken_word"]
            )
            
            # Ensure lowercase
            parsed["spoken"] = parsed["spoken"].lower()
            
            return parsed
        
        # Otherwise, build ADACS format from simple format
        try:
            adacs_entry = self.build_adacs_format(
                origin_text=parsed["text"],
                en_words=parsed["en_words"],
                context=parsed["context"],
                difficulty=parsed["difficulty"]
            )
            return adacs_entry
        except Exception as e:
            print(f"Error building ADACS format: {e}")
            return None


# V√≠ d·ª• s·ª≠ d·ª•ng
if __name__ == "__main__":
    from pronunciation_engine import PronunciationEngine
    
    # Kh·ªüi t·∫°o
    pronunciation = PronunciationEngine()
    processor = DataProcessor(pronunciation)
    
    # Test v·ªõi sample LLM response
    sample_response = """{
  "text": "Team Leader y√™u c·∫ßu update status c·ªßa Sprint Planning Meeting n√†y",
  "context": "sprint_planning",
  "en_words": ["Team", "Leader", "update", "status", "Sprint", "Planning", "Meeting"],
  "difficulty": "hard"
}"""
    
    print("=== Data Processor Test ===\n")
    print("Input LLM Response:")
    print(sample_response)
    print("\n" + "="*50 + "\n")
    
    # X·ª≠ l√Ω
    result = processor.process_llm_to_adacs(sample_response)
    
    if result:
        print("Output ADACS Format:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print("X·ª≠ l√Ω th·∫•t b·∫°i!")
